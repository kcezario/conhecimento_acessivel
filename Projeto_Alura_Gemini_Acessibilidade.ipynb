{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1E5rsB0hvdIrE3j-4O4ZFBAw90ufwZFx2",
      "authorship_tag": "ABX9TyNfVs6S985fIWXPpgerd2kI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcezario/conhecimento_acessivel/blob/main/Projeto_Alura_Gemini_Acessibilidade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conhecimento Acessível: Desvendando o Código\n",
        "O projeto \"Conhecimento Acessível\" utiliza o poder da Gemini API do Google para criar um assistente inclusivo, abrindo portas para a educação de pessoas com deficiência visual e não alfabetizados. O código, escrito em Python e executado no Google Colab, implementa diversas funcionalidades que tornam essa visão uma realidade."
      ],
      "metadata": {
        "id": "bmgMIYlBmzjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalação de Bibliotecas\n",
        "Instala bibliotecas essenciais para geração de texto, reconhecimento de voz, processamento de áudio e interação com a Wikipedia."
      ],
      "metadata": {
        "id": "x55LrQrDC1IB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-KfL5JjobIQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install -q -U SpeechRecognition\n",
        "!pip install -q -U faster-whisper\n",
        "!pip install -q -U wikipedia\n",
        "!pip install -q -U gTTS\n",
        "!pip install -q -U gTTS pydub"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importação de Módulos\n",
        "Importa módulos para manipulação de dados, interação com APIs, processamento de áudio, e integração com ambiente Jupyter e Google Colab.\n"
      ],
      "metadata": {
        "id": "vCzwwPaKC4nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "import wikipedia\n",
        "import time\n",
        "import inspect\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from gtts import gTTS\n",
        "from faster_whisper import WhisperModel\n",
        "from io import BytesIO\n",
        "from base64 import b64decode\n",
        "from google.colab import output\n",
        "from google.colab import userdata\n",
        "from IPython.display import Javascript\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "id": "aoBtCpHOosWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração da API do Google\n",
        "Define e configura a chave de API para utilização dos serviços de inteligência artificial do Google.\n"
      ],
      "metadata": {
        "id": "GK1-AjDmDBec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = userdata.get('SECRET_KEY')\n",
        "genai.configure(api_key=API_KEY)"
      ],
      "metadata": {
        "id": "fU6vJ0bik3LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de Gravação de Áudio\n",
        "Implementa uma função JavaScript para gravação de áudio no navegador, incluindo utilitários para conversão de blob para base64 e temporização.\n"
      ],
      "metadata": {
        "id": "X5t-BlNgDIMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Qoh1toBat6BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definições de Prompts para o Gemini\n",
        "Configura prompts específicos para interações baseadas em text-to-speech, definindo as instruções de comunicação do assistente em diversas situações com o usuário.\n"
      ],
      "metadata": {
        "id": "ds8r532YDOBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_gemini = {\n",
        "  'cumprimento': \"Você é um assistente simpático, e o texto que você gerar será lido por uma tecnologia de text-to-speech. Cumprimente o usuário. Mantenha o texto curto e sintético, simpático e pergunte o que ele quer saber hoje. Quero apenas a frase\",\n",
        "  'nao_entendi': \"Você é um assistente simpático que utiliza text-to-speech. Diga ao usuário que você não entendeu o comando e peça para ele repetir de forma gentil.\",\n",
        "  'despedida': \"Você é um assistente simpático que se comunica por text-to-speech. Despeça-se do usuário com um texto curto e gentil.\",\n",
        "  'resumo': \"Você é um assistente simpático que usa text-to-speech. Pergunte ao usuário se ele gostaria de ouvir um resumo do artigo.\",\n",
        "  'leitura_completa': \"Você é um assistente simpático que utiliza text-to-speech. Pergunte ao usuário se ele gostaria de ouvir o artigo completo.\",\n",
        "  '3_perguntas':\"Você é um assistente simpático que utiliza text-to-speech. Ofereça ao usuário três opções: ouvir um resumo do artigo, ouvir o artigo completo ou pesquisar outro assunto. Não diga (claro), ou (perfeitamente) ao começar a frase, comece oferecendo diretamente as opções\",\n",
        "  'esclarecimento': \"Você é um assistente simpático que usa text-to-speech. Pergunte ao usuário se ele deseja que algum ponto específico do artigo seja esclarecido.\",\n",
        "  'proximo_passo': \"Você é um assistente simpático que utiliza text-to-speech. Pergunte ao usuário o que ele gostaria de fazer agora, mas não ofereça nenhuma opção.\",\n",
        "  'novo_tema': \"Você é um assistente simpático que utiliza text-to-speech. Pergunte ao usuário qual tema ele gostaria de estudar ou entender. Não diga (claro), ou (perfeitamente) ao começar a frase\",\n",
        "  'erro_tema': \"Você é um assistente simpático que utiliza text-to-speech. Peça desculpas por não ter encontrado informações sobre esse tema, peça para o usuário dizer sobre qual outro tema ele gostaria de saber?\",\n",
        "  'perguntas': \"Você é um assistente simpático que utiliza text-to-speech. Pergunte ao usuário se ele gostaria de responder a algumas perguntas sobre o tema para testar seus conhecimentos.\",\n",
        "}"
      ],
      "metadata": {
        "id": "C0oN7hkcwbbv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de Log para Depuração\n",
        "Define uma função de logging que exibe informações sobre chamadas de função ou método, utilizável apenas se o modo de depuração estiver ativo.\n"
      ],
      "metadata": {
        "id": "wxXperXWDRoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# debug = True\n",
        "debug = False\n",
        "\n",
        "def log_function_call():\n",
        "    if debug:\n",
        "        caller_frame = inspect.currentframe().f_back\n",
        "        frame_info = inspect.getframeinfo(caller_frame)\n",
        "        file_name = os.path.basename(frame_info.filename)\n",
        "        cls_name = caller_frame.f_locals.get('self',\n",
        "                                             None).__class__.__name__ if 'self' in caller_frame.f_locals else None\n",
        "\n",
        "        if cls_name:\n",
        "            print(f\"Método {cls_name}.{frame_info.function}.\")\n",
        "        else:\n",
        "            print(f\"Função {frame_info.function}.\")"
      ],
      "metadata": {
        "id": "LcOM1EzHk6L4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Geração de Embedding\n",
        "Define uma função que gera embeddings de texto utilizando a API do Google GenerativeAI, ideal para consultas de recuperação de informação.\n"
      ],
      "metadata": {
        "id": "4BmWyP9EDVvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_embedding(texto, model=model_embed):\n",
        "  log_function_call()\n",
        "  \"\"\"Gera um embedding para o texto usando a API do Gemini.\"\"\"\n",
        "  return genai.embed_content(model=model, content=texto, task_type=\"RETRIEVAL_QUERY\")[\"embedding\"]"
      ],
      "metadata": {
        "id": "64kkOgxIU_Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração de Modelos e Intenções\n",
        "Inicializa modelos do Google GenerativeAI e cria DataFrames para categorizar as intenções do usuário e suas respostas, com a inclusão de embeddings gerados para facilitar o reconhecimento de intenções.\n"
      ],
      "metadata": {
        "id": "K36O3hJMDWR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_embed = \"models/embedding-001\"\n",
        "gemini_model = genai.GenerativeModel(\"gemini-1.0-pro-latest\")\n",
        "gemini_conversa = gemini_model.start_chat(history=[])\n",
        "\n",
        "df_intencoes = pd.DataFrame({\n",
        "    'titulo': [\"não entendi\", \"pesquisar\", \"sair\"],\n",
        "    'conteudo': [\"coisas sem sentido\", \"desejo que você pesquise, me fale sobre, quero saber, quero estudar\", \"quero sair, adeus, nos vemos, até logo\"]\n",
        "})\n",
        "\n",
        "df_3_perguntas = pd.DataFrame({\n",
        "    'titulo': [\"resumo\", \"artigo completo\", \"outro assunto\", \"sair\"],\n",
        "    'conteudo': [\"quero um resumo, resuma para mim, explique rapidamente\", \"leia tudo, quero saber mais, comece a leitura\", \"quero falar de outra coisa, quero entnder sobre outro assunto\", \"quero sair, adeus, nos vemos, até logo\"]\n",
        "})\n",
        "\n",
        "df_intencoes['embedding'] = df_intencoes['conteudo'].apply(gerar_embedding)\n",
        "df_3_perguntas['embedding'] = df_3_perguntas['conteudo'].apply(gerar_embedding)"
      ],
      "metadata": {
        "id": "oSU4bHxlk2_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração do Modelo Whisper\n",
        "Inicializa o modelo Whisper com tamanho especificado, configurando-o para operar na CPU e utilizando tipos de dados otimizados para performance.\n"
      ],
      "metadata": {
        "id": "lWVL4vrrDW31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "whisper_size = 'base'\n",
        "whisper_model = WhisperModel(whisper_size, device=\"cpu\", compute_type=\"int8\")\n"
      ],
      "metadata": {
        "id": "z3G4oruc6Y6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definição da Classe Chat\n",
        "Cria uma classe para gerenciar a interação com o usuário, incluindo métodos para início e menu principal, pesquisa de tópicos, resposta e transcrição de voz. Integra funcionalidades como o reconhecimento de intenções baseado em embeddings e o uso de modelos de geração de linguagem para resposta contextual.\n"
      ],
      "metadata": {
        "id": "CoiISVMPDa7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Chat:\n",
        "\n",
        "    def __init__(self):\n",
        "        log_function_call()\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "        self.comando = 'nao_entendi'\n",
        "        self.prompt = None\n",
        "        self.intencao = None\n",
        "        self.tema = None\n",
        "        self.conversa_iniciada = False\n",
        "        self.tema_novo = True\n",
        "        self.audio = None\n",
        "        self.artigo = None\n",
        "        self.resumo = None\n",
        "\n",
        "    def incio(self):\n",
        "        log_function_call()\n",
        "        \"\"\"Inicia o assistente de voz.\"\"\"\n",
        "        out = \"Iniciando o assistente...\"\n",
        "        print(out)\n",
        "        self.menu_principal()\n",
        "        out = \"Terminando o programa...\"\n",
        "        print(out)\n",
        "\n",
        "    def menu_principal(self):\n",
        "        log_function_call()\n",
        "        if self.comando != 'pesquisar':\n",
        "            if self.conversa_iniciada:\n",
        "                self.comando = 'nao_entendi'\n",
        "            else:\n",
        "                self.comando = 'cumprimento'\n",
        "                self.conversa_iniciada = True\n",
        "        else:\n",
        "            self.comando = 'erro_tema'\n",
        "\n",
        "        voltar = False\n",
        "        while not voltar:\n",
        "            self.pegar_resposta()\n",
        "            self.ouvir_escrever()\n",
        "            self.intencao = classificar_intencao(self.input, df_intencoes)\n",
        "            print(f'Intenção: {self.intencao}')\n",
        "            if self.intencao == 'pesquisar':\n",
        "                self.tema_novo = True\n",
        "                self.menu_pesquisa()\n",
        "            elif self.intencao == 'não entendi':\n",
        "                self.comando = 'nao_entendi'\n",
        "            else:\n",
        "                voltar = True\n",
        "\n",
        "    def menu_pesquisa(self):\n",
        "        log_function_call()\n",
        "        if self.tema_novo:\n",
        "            self.extrair_tema_wikipedia()\n",
        "            texto = f\"Pesquisando na Wikipédia: {self.tema}\"\n",
        "            self.pesquisar_wikipedia()\n",
        "            if self.comando != 'novo_tema':\n",
        "                self.comando = '3_perguntas'\n",
        "            print(texto)\n",
        "            play(texto)\n",
        "            self.tema_novo = False\n",
        "        else:\n",
        "            self.comando = 'novo_tema'\n",
        "\n",
        "        voltar = False\n",
        "        while not voltar:\n",
        "            self.pegar_resposta()\n",
        "            self.ouvir_escrever()\n",
        "            self.intencao = classificar_intencao(self.input, df_3_perguntas)\n",
        "            print(f'Intenção: {self.intencao}')\n",
        "            if self.intencao == 'resumo':\n",
        "                print(self.resumo)\n",
        "                play(self.resumo)\n",
        "                self.comando = 'proximo_passo'\n",
        "            elif self.intencao == 'artigo completo':\n",
        "                print(self.artigo)\n",
        "                play(self.artigo)\n",
        "                self.comando = 'proximo_passo'\n",
        "            elif self.intencao == 'outro assunto':\n",
        "                self.comando = 'novo_tema'\n",
        "                voltar = True\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    def extrair_tema_wikipedia(self):\n",
        "        log_function_call()\n",
        "        \"\"\"Pede ao Gemini para extrair o tema principal da frase para pesquisa na Wikipédia.\"\"\"\n",
        "        prompt = f\"\"\"Você é um assistente inteligente que ajuda a encontrar informações na Wikipédia.\n",
        "        Analise a seguinte frase e identifique o assunto principal que o usuário deseja pesquisar: \"{self.input}\".\n",
        "        Forneça apenas o assunto principal, formatado como uma única frase, ideal para ser usado como consulta na API da Wikipédia.\n",
        "        Por exemplo, se a frase for \"Gostaria de saber mais sobre a história da pizza\", a resposta deve ser \"História da pizza\".\n",
        "        Sua resposta:\"\"\"\n",
        "\n",
        "        resposta = gemini_conversa.send_message(prompt)\n",
        "        tema_wikipedia = resposta.text\n",
        "        self.tema = tema_wikipedia\n",
        "\n",
        "    def pesquisar_wikipedia(self):\n",
        "        log_function_call()\n",
        "        \"\"\"Pesquisa um tema na Wikipedia e retorna o título, resumo e conteúdo completo do artigo.\"\"\"\n",
        "        try:\n",
        "            wikipedia.set_lang(\"pt\")\n",
        "            resultados = wikipedia.search(self.tema)\n",
        "            if resultados:\n",
        "                pagina = wikipedia.page(resultados[0])\n",
        "                self.tema = pagina.title\n",
        "                self.resumo = pagina.summary\n",
        "                self.artigo = pagina.content\n",
        "                self.tema_novo = False\n",
        "                self.comando = '3_perguntas'\n",
        "            else:\n",
        "                out = \"Desculpe, não encontrei nenhum artigo na Wikipédia sobre esse tema.\"\n",
        "                print(out)\n",
        "                play(out)\n",
        "                self.tema = None\n",
        "                self.tema_novo = True\n",
        "                self.comando = 'pesquisar'\n",
        "\n",
        "        except wikipedia.exceptions.PageError:\n",
        "            out = \"Desculpe, não encontrei nenhum artigo na Wikipédia com esse título.\", None\n",
        "            print(out)\n",
        "            play(out)\n",
        "            self.tema = None\n",
        "            self.tema_novo = True\n",
        "            self.comando = 'pesquisar'\n",
        "\n",
        "    def falar_gemini(self, texto=\"\"):\n",
        "        log_function_call()\n",
        "        expressao = self.prompt + texto\n",
        "        resposta = gemini_conversa.send_message(expressao)\n",
        "        self.output = resposta.text\n",
        "        play(self.output)\n",
        "\n",
        "    def pegar_resposta(self):\n",
        "        log_function_call()\n",
        "        self.prompt = prompt_gemini[self.comando]\n",
        "        self.falar_gemini()\n",
        "\n",
        "    def ouvir_escrever(self,sec=3):\n",
        "        log_function_call()\n",
        "        audio = self.record()\n",
        "        self.input = transcrever_audio(audio)\n",
        "        print(f'Texto transcrito: {self.input}')\n",
        "\n",
        "    def record(self, sec=3):\n",
        "        log_function_call()\n",
        "        display(Javascript(RECORD))\n",
        "        sec += 1\n",
        "        s = output.eval_js('record(%d)' % (sec*1000))\n",
        "        play(\"aguarde\")\n",
        "        print(\"Pensando...\")\n",
        "        b = b64decode(s.split(',')[1])\n",
        "        return b\n",
        "\n",
        "    def pesquisar(self):\n",
        "        log_function_call()\n",
        "        self.tema_novo = True\n",
        "        self.menu_pesquisa()"
      ],
      "metadata": {
        "id": "H22LrgqmUa5X"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funções Auxiliares de Transcrição, Áudio e Classificação\n",
        "Implementa funções para transcrever áudio com tratamento de erros, reproduzir textos como áudio e classificar intenções do usuário usando embeddings, contribuindo para a interatividade e acessibilidade do assistente.\n"
      ],
      "metadata": {
        "id": "laFYRj49DrDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcrever_audio(audio_bytes):\n",
        "    log_function_call()\n",
        "    \"\"\"Transcreve áudio usando faster_whisper, tratando erros de áudio inválido.\"\"\"\n",
        "    max_tentativas = 3  # Número máximo de tentativas de transcrição\n",
        "    tentativa = 1\n",
        "    while tentativa <= max_tentativas:\n",
        "        try:\n",
        "            with BytesIO(audio_bytes) as audio_stream:\n",
        "                segments, info = whisper_model.transcribe(audio_stream, language=\"pt\")\n",
        "                texto = ' '.join([segment.text for segment in segments])\n",
        "                return texto\n",
        "        except InvalidDataError:\n",
        "            print(f\"Erro de áudio inválido. Tentativa {tentativa} de {max_tentativas}. Aguardando mais tempo...\")\n",
        "            time.sleep(2)  # Aguarda 2 segundos antes de tentar novamente\n",
        "            tentativa += 1\n",
        "    return \"\"  # Retorna vazio se todas as tentativas falharem\n",
        "\n",
        "def play(text):\n",
        "    log_function_call()\n",
        "    text = \"   \" + text\n",
        "    tts = gTTS(text, lang='pt')\n",
        "    tts.save('output.mp3')\n",
        "    audio_segment = AudioSegment.from_mp3('output.mp3')\n",
        "    duration_seconds = len(audio_segment) / 1000.0  # duração em segundos\n",
        "    display(Audio('output.mp3', autoplay=True))\n",
        "    time.sleep(duration_seconds)\n",
        "\n",
        "def classificar_intencao(consulta, df, model=model_embed):\n",
        "    log_function_call()\n",
        "    \"\"\"Classifica a intenção do usuário com base na similaridade de embeddings.\"\"\"\n",
        "    embedding_da_consulta = gerar_embedding(consulta, model)\n",
        "    produtos_escalares = np.dot(np.stack(df[\"embedding\"]), embedding_da_consulta)\n",
        "    indice = np.argmax(produtos_escalares)\n",
        "    return df.iloc[indice][\"titulo\"]"
      ],
      "metadata": {
        "id": "3Xiw9RtbDjts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inicialização e Execução do Chat\n",
        "Cria uma instância da classe `Chat` e inicia a interação com o usuário... e finalmente, dá o pontapé inicial no assistente de voz!\n"
      ],
      "metadata": {
        "id": "yEpXUmoeD9Di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = Chat()\n",
        "chat.incio()"
      ],
      "metadata": {
        "id": "B0_-ylyzUkZM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}