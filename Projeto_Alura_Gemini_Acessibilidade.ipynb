{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1E5rsB0hvdIrE3j-4O4ZFBAw90ufwZFx2",
      "authorship_tag": "ABX9TyN5NvsiSMS0mikZaGYrKRQI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcezario/conhecimento_acessivel/blob/main/Projeto_Alura_Gemini_Acessibilidade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H-KfL5JjobIQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install -q -U SpeechRecognition\n",
        "!pip install -q -U faster-whisper\n",
        "!pip install -q -U wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import sys\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "import wikipedia\n",
        "from faster_whisper import WhisperModel\n",
        "from io import BytesIO\n",
        "from base64 import b64decode\n",
        "from google.colab import output\n",
        "from google.colab import userdata\n",
        "from IPython.display import Javascript"
      ],
      "metadata": {
        "id": "aoBtCpHOosWQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = userdata.get('SECRET_KEY')\n",
        "genai.configure(api_key=API_KEY)"
      ],
      "metadata": {
        "id": "fU6vJ0bik3LD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Qoh1toBat6BC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_gemini = {\n",
        "  'cumprimento': \"Você é um assistente simpático, e o texto que você gerar será lido por uma tecnologia de text-to-speech. Cumprimente o usuário. Mantenha o texto curto, simpático e pergunte o que ele quer saber hoje.\",\n",
        "  'nao_entendi': \"Você é um assistente simpático que utiliza text-to-speech. Diga ao usuário que você não entendeu o comando e peça para ele repetir de forma gentil.\",\n",
        "  'despedida': \"Você é um assistente simpático que se comunica por text-to-speech. Despeça-se do usuário com um texto curto e gentil.\",\n",
        "  'resumo': \"Você é um assistente simpático que usa text-to-speech. Pergunte ao usuário se ele gostaria de ouvir um resumo do artigo.\",\n",
        "  'leitura_completa': \"Você é um assistente simpático que utiliza text-to-speech. Pergunte ao usuário se ele gostaria de ouvir o artigo completo.\",\n",
        "  '3_perguntas':\"Você é um assistente simpático que utiliza text-to-speech. Ofereça ao usuário três opções: ouvir um resumo do artigo, ouvir o artigo completo ou pesquisar outro assunto.\",\n",
        "  'esclarecimento': \"Você é um assistente simpático que usa text-to-speech. Pergunte ao usuário se ele deseja que algum ponto específico do artigo seja esclarecido.\",\n",
        "  'perguntas': \"Você é um assistente simpático que utiliza text-to-speech. Pergunte ao usuário se ele gostaria de responder a algumas perguntas sobre o tema para testar seus conhecimentos.\"\n",
        "}"
      ],
      "metadata": {
        "id": "C0oN7hkcwbbv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_model = genai.GenerativeModel(\"gemini-1.0-pro-latest\")  # Modelo Gemini\n",
        "gemini_conversa = gemini_model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "XeGAjgBIyvvt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record(sec=3, conversa_iniciada=False):\n",
        "  if conversa_iniciada:\n",
        "    comando = 'nao_entendi'\n",
        "  else:\n",
        "    comando = 'cumprimento'\n",
        "  gemini_assist = falar_gemini(comando)\n",
        "  conversa_iniciada = True\n",
        "  print(gemini_assist)\n",
        "  display(Javascript(RECORD))\n",
        "  sec += 1\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  print(\"Pensando...\")\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  return b #byte stream"
      ],
      "metadata": {
        "id": "S-hC2bbmqJzk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para transcrever áudio usando faster_whisper\n",
        "def transcrever_audio(audio_bytes):\n",
        "  with BytesIO(audio_bytes) as audio_stream:\n",
        "    segments, info = whisper_model.transcribe(audio_stream, language=\"pt\")\n",
        "    texto = ' '.join([segment.text for segment in segments])\n",
        "    return texto"
      ],
      "metadata": {
        "id": "6KnRa2aEuhHk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Função para capturar áudio e detectar a palavra de ativação\n",
        "# def capturar_e_detectar():\n",
        "#   global listening_for_wake_word\n",
        "#   listening_for_wake_word = True\n",
        "#   while listening_for_wake_word:\n",
        "#     audio_bytes = record(sec=3)  # Grava por 3 segundos\n",
        "#     texto = transcrever_audio(audio_bytes)\n",
        "#     texto = re.sub(r'[^a-zA-ZÀ-ÿ\\s]', '', texto)\n",
        "#     if WAKE_WORD in texto.lower():\n",
        "#       print(\"Palavra de ativação detectada!\")\n",
        "#       listening_for_wake_word = False\n",
        "#       return capturar_comando()\n",
        "#     else:\n",
        "#       print(\"Aguardando palavra de ativação...\")"
      ],
      "metadata": {
        "id": "PHAjFZVaujaf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def executar_acao(intencao, comando):\n",
        "    \"\"\"Executa a ação correspondente à intenção do usuário.\"\"\"\n",
        "    global artigo_atual\n",
        "    if intencao == 'não entendi':\n",
        "        return falar_gemini('nao_entendi')\n",
        "    elif intencao == 'pesquisar':\n",
        "        tema_wikipedia = extrair_tema_wikipedia(comando)\n",
        "        artigo_atual = pesquisar_wikipedia(tema_wikipedia)\n",
        "        return falar_gemini('3_perguntas')\n",
        "    elif intencao == 'sair':\n",
        "        resposta = falar_gemini('despedida')\n",
        "        print(resposta)\n",
        "        exit()\n",
        "    elif intencao == '3_perguntas':\n",
        "        return artigo_atual  # Retorna o artigo armazenado\n",
        "    else:\n",
        "        return \"Desculpe, não entendi o seu pedido.\""
      ],
      "metadata": {
        "id": "rMY4rTCQCuSb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def menu_principal():\n",
        "  \"\"\"Gerencia o menu principal do assistente.\"\"\"\n",
        "  df_intencoes['embedding'] = df_intencoes['conteudo'].apply(gerar_embedding) # Gera os embeddings ao entrar no menu\n",
        "  while True:\n",
        "    audio_bytes = record(sec=5)\n",
        "    texto = transcrever_audio(audio_bytes)\n",
        "    texto = re.sub(r'[^a-zA-ZÀ-ÿ\\s]', '', texto).lower()\n",
        "    print(\"Transcrição:\", texto)\n",
        "\n",
        "    if not texto or texto.isspace():\n",
        "      print(\"Resposta do Gemini:\", falar_gemini('nao_entendi'))\n",
        "      continue\n",
        "\n",
        "    intencao = classificar_intencao(texto, df_intencoes)\n",
        "    print(\"Intenção:\", intencao)\n",
        "\n",
        "    if intencao == 'sair':\n",
        "      break\n",
        "    elif intencao == 'pesquisar':\n",
        "      menu_pesquisa(texto)\n",
        "    else:\n",
        "      resposta = executar_acao(intencao, texto)\n",
        "      print(\"Resposta do Gemini:\", resposta)"
      ],
      "metadata": {
        "id": "HWJ45XNhkRkh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def menu_pesquisa(comando):\n",
        "  \"\"\"Gerencia o menu de pesquisa de artigos.\"\"\"\n",
        "  global artigo_atual\n",
        "  tema_wikipedia = extrair_tema_wikipedia(comando)\n",
        "  artigo_atual = pesquisar_wikipedia(tema_wikipedia)\n",
        "  print(\"Resposta do Gemini:\", falar_gemini('3_perguntas'))\n",
        "\n",
        "  df_3_perguntas['embedding'] = df_3_perguntas['conteudo'].apply(gerar_embedding) # Gera os embeddings ao entrar no menu\n",
        "  while True:\n",
        "    audio_bytes = record(sec=5)\n",
        "    texto = transcrever_audio(audio_bytes)\n",
        "    texto = re.sub(r'[^a-zA-ZÀ-ÿ\\s]', '', texto).lower()\n",
        "    print(\"Transcrição:\", texto)\n",
        "\n",
        "    if not texto or texto.isspace():\n",
        "      print(\"Resposta do Gemini:\", falar_gemini('nao_entendi'))\n",
        "      continue\n",
        "\n",
        "    intencao = classificar_intencao(texto, df_3_perguntas)\n",
        "    print(\"Intenção:\", intencao)\n",
        "\n",
        "    if intencao == 'outro assunto':\n",
        "      break\n",
        "\n",
        "    resposta = executar_acao(intencao, texto)\n",
        "    print(\"Resposta do Gemini:\", resposta)"
      ],
      "metadata": {
        "id": "HDkuLzookRaA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def capturar_e_detectar():\n",
        "  \"\"\"Inicia o assistente de voz.\"\"\"\n",
        "  print(\"Iniciando o assistente...\")\n",
        "  menu_principal()\n",
        "  print(\"Terminando o programa...\")"
      ],
      "metadata": {
        "id": "7qGb7Z3tCpsV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def capturar_comando():\n",
        "  print(\"Fale seu comando...\")\n",
        "  audio_bytes = record(sec=5)  # Grava por 5 segundos\n",
        "  comando = transcrever_audio(audio_bytes)\n",
        "  resposta = obter_resposta_gemini(comando)\n",
        "  print(\"Resposta do Gemini:\", resposta)\n",
        "  return resposta"
      ],
      "metadata": {
        "id": "58D9KnadumyU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para enviar o comando para a API do Gemini e obter a resposta\n",
        "def obter_resposta_gemini(comando):\n",
        "  # Envie o comando e obtenha a resposta\n",
        "  gemini_conversa.send_message(comando)\n",
        "  resposta = gemini_conversa.last_text\n",
        "  return resposta"
      ],
      "metadata": {
        "id": "vQLwCY6Uyc7x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def falar_gemini(chave_prompt, texto=\"\"):\n",
        "  prompt = prompt_gemini.get(chave_prompt)\n",
        "  if not prompt:\n",
        "    prompt = prompt_gemini.get(nao_entendi)\n",
        "  resposta = gemini_conversa.send_message(prompt)\n",
        "  retorno = resposta.text\n",
        "  return retorno"
      ],
      "metadata": {
        "id": "TPw9qXPPxGhI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_embed = \"models/embedding-001\"\n",
        "\n",
        "df_intencoes = pd.DataFrame({\n",
        "    'titulo': [\"não entendi\", \"pesquisar\", \"sair\"],\n",
        "    'conteudo': [\"coisas sem sentido\", \"desejo que você pesquise, me fale sobre, quero saber, quero estudar\", \"quero sair, adeus, nos vemos, até logo\"]\n",
        "})\n",
        "\n",
        "df_3_perguntas = pd.DataFrame({\n",
        "    'titulo': [\"resumo\", \"artigo completo\", \"outro assunto\"],\n",
        "    'conteudo': [\"quero um resumo, resuma para mim, explique rapidamente\", \"leia tudo, quero saber mais, comece a leitura\", \"quero falar de outra coisa, quero entnder sobre outro assunto\"]\n",
        "})\n",
        "\n",
        "def gerar_embedding(texto, model=model_embed):\n",
        "  \"\"\"Gera um embedding para o texto usando a API do Gemini.\"\"\"\n",
        "  return genai.embed_content(model=model, content=texto, task_type=\"RETRIEVAL_QUERY\")[\"embedding\"]"
      ],
      "metadata": {
        "id": "EDRJeNKV_ow8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classificar_intencao(consulta, df, model=model_embed):\n",
        "  \"\"\"Classifica a intenção do usuário com base na similaridade de embeddings.\"\"\"\n",
        "  embedding_da_consulta = gerar_embedding(consulta, model)\n",
        "  produtos_escalares = np.dot(np.stack(df[\"embedding\"]), embedding_da_consulta)\n",
        "  indice = np.argmax(produtos_escalares)\n",
        "  return df.iloc[indice][\"titulo\"]"
      ],
      "metadata": {
        "id": "YeM7yX_TArAe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iid4uxcmhfMw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pesquisar_wikipedia(tema):\n",
        "  \"\"\"Pesquisa um tema na Wikipedia e retorna um resumo.\"\"\"\n",
        "  try:\n",
        "    wikipedia.set_lang(\"pt\")\n",
        "    resultados = wikipedia.search(tema)\n",
        "    if resultados:\n",
        "      pagina = wikipedia.page(resultados[0])\n",
        "      resposta = falar_gemini('resumo')\n",
        "      resposta += f\" Aqui está um resumo sobre {pagina.title}: {pagina.summary}\"\n",
        "      return resposta\n",
        "    else:\n",
        "      return \"Desculpe, não encontrei nenhum artigo na Wikipédia sobre esse tema.\"\n",
        "  except wikipedia.exceptions.DisambiguationError as e:\n",
        "    return f\"Sua pesquisa é ambígua. Poderia se referir a: {e.options}\"\n",
        "  except wikipedia.exceptions.PageError:\n",
        "    return \"Desculpe, não encontrei nenhum artigo na Wikipédia com esse título.\"\n"
      ],
      "metadata": {
        "id": "dKjObCJObwq0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extrair_tema_wikipedia(texto):\n",
        "  \"\"\"Pede ao Gemini para extrair o tema principal da frase para pesquisa na Wikipédia.\"\"\"\n",
        "  prompt = f\"\"\"Você é um assistente inteligente que ajuda a encontrar informações na Wikipédia.\n",
        "  Analise a seguinte frase e identifique o assunto principal que o usuário deseja pesquisar: \"{texto}\".\n",
        "  Forneça apenas o assunto principal, formatado como uma única frase, ideal para ser usado como consulta na API da Wikipédia.\n",
        "  Por exemplo, se a frase for \"Gostaria de saber mais sobre a história da pizza\", a resposta deve ser \"História da pizza\".\n",
        "  Sua resposta:\"\"\"\n",
        "\n",
        "  resposta = gemini_conversa.send_message(prompt)\n",
        "  tema_wikipedia = resposta.text\n",
        "  return tema_wikipedia\n"
      ],
      "metadata": {
        "id": "ko_jT7ZiduZ8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar modelo Whisper para reconhecimento de voz\n",
        "whisper_size = 'base'\n",
        "whisper_model = WhisperModel(whisper_size, device=\"cpu\", compute_type=\"int8\")\n",
        "\n",
        "print(\"Configuração e autenticação concluídas!\")"
      ],
      "metadata": {
        "id": "zpXERR1lmlRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c10570c-115a-4039-aaa3-4e77044fb28c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuração e autenticação concluídas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciar a captura de áudio e detecção da palavra de ativação\n",
        "\n",
        "capturar_e_detectar()\n",
        "print(\"Fase 3 concluída!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "xuRhSMsrupZo",
        "outputId": "0a5a4554-9b07-41ab-b45b-c209d8925c23"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando o assistente...\n",
            "Olá! Prazer em conhecê-lo. O que você gostaria de saber hoje?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pensando...\n",
            "Transcrição:  me fale sobre a segunda guerra mundial\n",
            "Intenção: pesquisar\n",
            "Resposta do Gemini: Você gostaria de:\n",
            "\n",
            "1. Ouvir um resumo do artigo\n",
            "2. Ouvir o artigo completo\n",
            "3. Pesquisar outro assunto\n",
            "Olá! Como posso ajudar?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7814415195e8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Iniciar a captura de áudio e detecção da palavra de ativação\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcapturar_e_detectar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fase 3 concluída!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-5fece24f440e>\u001b[0m in \u001b[0;36mcapturar_e_detectar\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;34m\"\"\"Inicia o assistente de voz.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iniciando o assistente...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mmenu_principal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Terminando o programa...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-8dbfe3ba854e>\u001b[0m in \u001b[0;36mmenu_principal\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mintencao\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pesquisar'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mmenu_pesquisa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mresposta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutar_acao\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintencao\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-af64874b26ed>\u001b[0m in \u001b[0;36mmenu_pesquisa\u001b[0;34m(comando)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mdf_3_perguntas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embedding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_3_perguntas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conteudo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgerar_embedding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Gera os embeddings ao entrar no menu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0maudio_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtexto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscrever_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtexto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^a-zA-ZÀ-ÿ\\s]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-5db3c3f167a8>\u001b[0m in \u001b[0;36mrecord\u001b[0;34m(sec, conversa_iniciada)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJavascript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRECORD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0msec\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'record(%d)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pensando...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}